{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of models by means of lexical substitution</b><br/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "import operator\n",
    "from functools import reduce\n",
    "import pickle\n",
    "#os.listdir('small_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def prod(it):\n",
    "    return reduce(operator.mul, it, 1)\n",
    "\n",
    "def get_candidate_dict():\n",
    "    with open('lst/lst.gold.candidates','r') as f:\n",
    "        lines = map(str.strip,f.readlines())\n",
    "        d = defaultdict(list)\n",
    "        for line in lines:\n",
    "            target, candidates = line.split('::')\n",
    "            d[target] = candidates.split(';')\n",
    "    return d\n",
    "\n",
    "def cos(v1, v2):\n",
    "    # Calculates the vector cosine similarity between v1 and v2\n",
    "    # Returns a value between -1 and 1, 1 meaning exactly same\n",
    "    #  and -1 meaning exactly opposite.\n",
    "    assert len(v1) == len(v2)\n",
    "    numerator = sum([v1[i]*v2[i] for i in range(len(v1))])\n",
    "    denominator = np.sqrt(sum([x**2 for x in v1])) \\\n",
    "                * np.sqrt(sum([x**2 for x in v2]))\n",
    "    \n",
    "    return (numerator/denominator)\n",
    "\n",
    "def pcos(v1,v2):\n",
    "    return 0.5*(cos(v1,v2)+1)\n",
    "\n",
    "def add(target, sub, context):\n",
    "    # target: embedding of target word\n",
    "    # sub   : embedding of substitution word\n",
    "    # context: list of embeddings of context words\n",
    "    return (cos(sub,target) + sum([cos(sub,c) for c in context]))/(len(context)+1)\n",
    "\n",
    "def mult(target, sub,context):\n",
    "    return (pcos(sub,target) * prod([pcos(sub, c) for c in context]))**(1/(2*len(context)))\n",
    "\n",
    "def load_skipgram():\n",
    "   \n",
    "    with open('skipgram_embedding.matrix','rb') as f:\n",
    "        embed_mat = pickle.load(f)\n",
    "    print(\"Embedding loaded.\")\n",
    "    with open('i2w.skip','rb') as f:\n",
    "        int2word_skip = pickle.load(f)\n",
    "    with open('w2i.skip','rb') as f:\n",
    "        word2int_skip = pickle.load(f)\n",
    "    return embed_mat, int2word_skip, word2int_skip\n",
    "\n",
    "def get_embedding(word, embed_mat, word2int):\n",
    "    try:\n",
    "        idx = word2int[word]\n",
    "    except KeyError:\n",
    "        # KeyError will return the UNK vector\n",
    "        idx = word2int['<UNK>']\n",
    "    return embed_mat[idx,:]\n",
    "\n",
    "def word2embed_skip(embedding_mat, w2i,*input_words):\n",
    "\n",
    "    if len(input_words) > 1:\n",
    "        result = [get_embedding(x, embedding_mat, w2i) for x in input_words]\n",
    "        result = [x for x in result if x is not None]\n",
    "    else:\n",
    "        result = get_embedding(input_words[0], embedding_mat, w2i)\n",
    "    return result\n",
    "\n",
    "def result2line(target, sent_id, sorted_results):\n",
    "    line = 'RANKED\\t{} {}\\t'.format(target,sent_id)\n",
    "    for (word, score) in sorted_results:\n",
    "        line += '{} {}\\t'.format(word,score)\n",
    "    line +='\\n'\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding loaded.\n",
      "VOCABULARY HAS SIZE 13130\n",
      "EVAL 0/1710\n",
      "avg it: 0 sec\n",
      "EVAL 100/1710\n",
      "avg it: 4.0099620819091796e-05 sec\n",
      "EVAL 200/1710\n",
      "avg it: 3.6215782165527345e-05 sec\n",
      "EVAL 300/1710\n",
      "avg it: 3.5810470581054685e-05 sec\n",
      "EVAL 400/1710\n",
      "avg it: 3.4759044647216795e-05 sec\n",
      "EVAL 500/1710\n",
      "avg it: 3.635406494140625e-05 sec\n",
      "EVAL 600/1710\n",
      "avg it: 3.6938985188802084e-05 sec\n",
      "EVAL 700/1710\n",
      "avg it: 3.6513124193464006e-05 sec\n",
      "EVAL 800/1710\n",
      "avg it: 3.563851118087768e-05 sec\n",
      "EVAL 900/1710\n",
      "avg it: 3.57712639702691e-05 sec\n",
      "EVAL 1000/1710\n",
      "avg it: 3.5758256912231444e-05 sec\n",
      "EVAL 1100/1710\n",
      "avg it: 3.636425191705877e-05 sec\n",
      "EVAL 1200/1710\n",
      "avg it: 3.691732883453369e-05 sec\n",
      "EVAL 1300/1710\n",
      "avg it: 3.699229313777043e-05 sec\n",
      "EVAL 1400/1710\n",
      "avg it: 3.6839246749877926e-05 sec\n",
      "EVAL 1500/1710\n",
      "avg it: 3.66363525390625e-05 sec\n",
      "EVAL 1600/1710\n",
      "avg it: 3.6673694849014284e-05 sec\n",
      "EVAL 1700/1710\n",
      "avg it: 3.669107661527746e-05 sec\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# Lexical substitution model\n",
    "def eval_model(load_model_func):\n",
    "    # varname_e means embedded vector of word in var <varname>\n",
    "    cand_dict = get_candidate_dict()\n",
    "    punc_set = ['.',',',':',';','_','-']\n",
    "    embedding_mat, i2w,w2i = load_model_func()\n",
    "    print(\"VOCABULARY HAS SIZE {}\".format(embedding_mat.shape[0]))\n",
    "    with open('lst/lst_test.preprocessed','r') as f:\n",
    "        lines = list(map(str.strip,f.readlines()))\n",
    "    \n",
    "   # with open('lst.out','w') as f:\n",
    "    \n",
    "    add_lines = []\n",
    "    mult_lines = []\n",
    "    global THING\n",
    "    THING = 0\n",
    "    st = 0\n",
    "    dt = 0\n",
    "    l = len(lines)\n",
    "    \n",
    "    for i,line in enumerate(lines):\n",
    "        s = time.time()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(\"EVAL {}/{}\".format(i,l))\n",
    "            print(\"avg it: {} sec\".format(dt))\n",
    "        target, s_id, pos, sent = line.split('\\t')\n",
    "        candidates = cand_dict[target]\n",
    "        context = [x for i,x in enumerate(sent.split(' ')) if i != int(pos) and x not in punc_set]\n",
    "        #print(i,'context')\n",
    "        context_e = [get_embedding(c,embedding_mat, w2i) for c in context]\n",
    "        #print(i,'target')\n",
    "        target_e = get_embedding(target.split('.')[0],embedding_mat, w2i)\n",
    "        \n",
    "        results_add = {}\n",
    "        results_mult = {}\n",
    "        \n",
    "        for sub in candidates:\n",
    "            #print(sub)\n",
    "            sub_e = get_embedding(sub,embedding_mat, w2i)\n",
    "            \n",
    "            #add_score = add(target_e, sub_e, context_e)\n",
    "            #mult_score = mult(target_e, sub_e, context_e)\n",
    "            #results_add[sub] = add_score\n",
    "            #results_mult[sub] = mult_score\n",
    "        #add_sort = sorted(results_add.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        #mult_sort = sorted(results_mult.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        \n",
    "        #add_lines.append(result2line(target,s_id,add_sort))\n",
    "        #mult_lines.append(result2line(target,s_id, mult_sort))\n",
    "        st += time.time() - s\n",
    "        dt = st / (i+1)\n",
    "    #add_file = open('lst_add.out','w')\n",
    "    #for line in add_lines:\n",
    "        #add_file.write(line)\n",
    "    #add_file.close()\n",
    "    #mult_file = open('lst_mult.out','w')\n",
    "    #for line in mult_lines:\n",
    "        #mult_file.write(line)\n",
    "    #mult_file.close()\n",
    "    print('DONE.')\n",
    "            \n",
    "    \n",
    "eval_model(load_skipgram)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13130, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mat, i2w,w2i = load_skipgram()\n",
    "#word2embed_skip(embedding_mat, w2i, '<UNK>')\n",
    "embedding_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4e9c1db5c2f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['solid 0', '6225331702036535']\n",
      "8\n",
      "RANKED\tsolid.a 1081\tdependable 0.20588213820742507\tsturdy 0.20588213820742507\tcemented 0.20588213820742507\tset 0.09908956119204067\tgood 0.0763110130114627\tvalid 0.0680356265077055\tsolid 0.06225331702036535\tdry 0.058458392485820035\trespectable 0.057812489214126773\tfirm 0.05410070791891403\tsound 0.052414873687468035\tsecure 0.052180210545788086\tconvincing 0.05210727499444877\tstrong 0.04921971025685812\tgenuine 0.04740551441274434\tstable 0.04197998682295047\tsubstantive 0.03879461806182938\taccurate 0.03703415098676676\treliable 0.03683742150357246\tconcrete 0.035923298452400054\trigid 0.027926648439387802\tfixed 0.02377629184580367\thard 0.020089884795165155\tsubstantial 0.0060076314035449755\t\n",
      "\n",
      "['solid 0', '8974272608098804']\n",
      "3\n",
      "RANKED\tsolid.a 1082\tset 0.09039260943000081\tsolid 0.08974272608098804\trespectable 0.07468367570254071\tgood 0.06869220921774132\tgenuine 0.06706521386505994\tsound 0.05848737712814536\tfixed 0.053576417404430525\tsubstantive 0.04947083899544619\tdependable 0.04410213401351932\tsturdy 0.04410213401351932\tcemented 0.04410213401351932\tstrong 0.03996249283744747\tstable 0.036673675665006275\tconvincing 0.03389010259752676\tconcrete 0.03329715611706338\tdry 0.031196023305871814\tfirm 0.029658288578650507\tsecure 0.029236616541829834\trigid 0.019704269605728963\thard 0.015974339257148765\tvalid 0.013202106576906063\taccurate 0.010891964457831867\treliable 0.010677287332634119\tsubstantial 0.00693599494308187\t\n",
      "\n",
      "['solid 0', '9163447924452729']\n",
      "5\n",
      "RANKED\tsolid.a 1083\tdependable 0.1707225995137291\tsturdy 0.1707225995137291\tcemented 0.1707225995137291\tsolid 0.09163447924452729\tset 0.08675596511404164\tgood 0.08044762832701051\tvalid 0.06564336752344148\tsound 0.06144757332672185\trespectable 0.051324354217702484\tsecure 0.04991674212406118\tdry 0.04856137299414452\tfirm 0.0475818682684096\tconvincing 0.04604423715069679\tstable 0.044768029547602166\thard 0.03487332548582895\trigid 0.032270620104673194\tconcrete 0.026919054843062996\treliable 0.025424100393047596\tstrong 0.023431077753369996\tsubstantive 0.02286591888122519\tgenuine 0.020157995035093107\taccurate 0.01252012732630063\tfixed 0.007918641683875004\tsubstantial 0.0009481639204369895\t\n",
      "\n",
      "['solid 0', '6824681211333276']\n",
      "7\n",
      "RANKED\tsolid.a 1084\tdependable 0.130635629309099\tsturdy 0.130635629309099\tcemented 0.130635629309099\tset 0.07622050345534491\tgood 0.07578207821690472\tsolid 0.06824681211333276\tstrong 0.06595621129741323\tsecure 0.05697445428693563\tdry 0.05120546304487648\tvalid 0.047159823882970506\tfixed 0.04484249137534609\tgenuine 0.0393422230573379\trespectable 0.03718281626200956\tstable 0.03415025069554036\tfirm 0.03343638882824771\tsubstantive 0.032488372614776155\tsound 0.028303105408474603\tconcrete 0.027514201388122415\taccurate 0.024444136526470827\treliable 0.020012725295324878\tconvincing 0.019868540102929325\trigid 0.016719246305755543\thard 0.016308294178300053\tsubstantial 0.0001871175683055487\t\n",
      "\n",
      "['solid 0', '5373528597774239']\n",
      "10\n",
      "RANKED\tsolid.a 1085\tdependable 0.13019816813789703\tsturdy 0.13019816813789703\tcemented 0.13019816813789703\tgood 0.0629582585637912\tset 0.06257703509148398\tfirm 0.05998138736914158\tsecure 0.05482156408414018\tvalid 0.05457279463123594\tsolid 0.05373528597774239\tdry 0.05181894280176833\tgenuine 0.0506153496327242\tsound 0.04671943684840088\tsubstantive 0.042399940134847554\thard 0.04142329339861778\tstable 0.04079104854235408\trespectable 0.0391308576852493\tstrong 0.03501431308510316\tconcrete 0.03352626014836176\tfixed 0.03252473666069244\tconvincing 0.027239903843109415\taccurate 0.022021557652207424\trigid 0.012999024283213374\treliable 0.012428604216201957\tsubstantial 0.011104465173435435\t\n",
      "\n",
      "['solid 0', '6787242010223753']\n",
      "5\n",
      "RANKED\tsolid.a 1086\tdependable 0.15835751344657412\tsturdy 0.15835751344657412\tcemented 0.15835751344657412\tsolid 0.06787242010223753\tset 0.06443019746601569\tvalid 0.055162720828445894\tgenuine 0.04776637523977172\tdry 0.04628746180654485\tgood 0.046006007610790246\tsecure 0.04565106616574666\tconvincing 0.04486340062972083\tstable 0.04435593647077666\tfixed 0.040878571172030455\tstrong 0.038366383498383234\tsubstantive 0.035940471891339115\tsound 0.03543096166650618\thard 0.03433209135640988\tconcrete 0.03355732614918554\taccurate 0.028895913378741957\trespectable 0.024801974856509548\tfirm 0.021667926326807457\treliable 0.021460028501450994\tsubstantial 0.01040867033595418\trigid 0.0094983466158457\t\n",
      "\n",
      "['solid 0', '6521487354413193']\n",
      "6\n",
      "RANKED\tsolid.a 1087\tdependable 0.13268401876254976\tsturdy 0.13268401876254976\tcemented 0.13268401876254976\tset 0.0932066329418212\tsolid 0.06521487354413193\tgood 0.06268381444088901\tsound 0.061382298141661615\tstable 0.06045934185821524\trespectable 0.056100986009494376\tgenuine 0.05074856262962107\tdry 0.043695042517304654\tsecure 0.04292667050990458\tconvincing 0.042892666619857044\tvalid 0.04065858313054052\tstrong 0.039100048003140354\trigid 0.03707965368791527\tfixed 0.03013330414230419\taccurate 0.029370369219514712\thard 0.029341049510168703\treliable 0.027062934574004688\tsubstantive 0.024122851061818645\tconcrete 0.023461671259704848\tfirm 0.020252147820582597\tsubstantial 0.013176377665998636\t\n",
      "\n",
      "['solid 0', '57785544525822005']\n",
      "8\n",
      "RANKED\tsolid.a 1089\tdependable 0.06863143035501104\tsturdy 0.06863143035501104\tcemented 0.06863143035501104\tset 0.06817181626070969\tgood 0.0597499696219078\tvalid 0.05788898429754391\tsolid 0.057785544525822005\tstable 0.04933975060065192\tgenuine 0.04899352458128345\tsecure 0.04839503483846271\tdry 0.04423092637215098\thard 0.041710380461310974\taccurate 0.040060135822445754\tfixed 0.038208387527149175\tsound 0.03772250122149756\treliable 0.037063526837983224\tconcrete 0.0356972916364894\trigid 0.029943041583835584\tstrong 0.029407283663909017\trespectable 0.02692436375249999\tconvincing 0.024420534946545672\tfirm 0.019573491494305567\tsubstantive 0.018235457845668327\tsubstantial -0.0024775343409952867\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rewrites wrong output files to right format.\n",
    "with open('lst_addw3.out','r') as f:\n",
    "    lines = f.readlines()\n",
    "with open('lst_add1.out','w') as f:\n",
    "    i = 0\n",
    "    \n",
    "    for line in lines:\n",
    "        if i < 100:\n",
    "            b = line.split('\\t')\n",
    "            #print(b[1].split('.')[0])\n",
    "            t = b[1].split('.')[0]\n",
    "            for i,w in enumerate(b[3:]):\n",
    "                #print(w.split('0.')[0].strip())\n",
    "                if w.split('0.')[0].strip() == t:\n",
    "                    print(w.split('.0'))\n",
    "                    del b[i+3]\n",
    "                    print(i+3)\n",
    "                    print(line)\n",
    "                    \n",
    "            #print([x.split(' ')[0] for x in b[3:]])\n",
    "            s = b[0]+'\\t'+b[1]+' '+b[2]\n",
    "            for w in b[3:]:\n",
    "                s += '\\t'+w\n",
    "            #print(s)\n",
    "            f.write(s)\n",
    "            #i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n",
      "0\n",
      "[(2, 3), (5, 6)]\n"
     ]
    }
   ],
   "source": [
    "a = [(1,2),(2,3),(5,6)]\n",
    "for i,b in enumerate(a):\n",
    "    if 1 in b:\n",
    "        print(b)\n",
    "        print(i)\n",
    "        del a[i]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from skip_checkpoints/text8.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Restoring the model\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph('skip_checkpoints/text8.ckpt.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('skip_checkpoints'))\n",
    "graph = tf.get_default_graph()\n",
    "embed_tensor = graph.get_tensor_by_name('embedding:0')\n",
    "embedding_matrix= sess.run(embed_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lst_test.gold',\n",
       " 'lst.gold.candidates',\n",
       " 'score.pl',\n",
       " 'generalized_average_precision.py',\n",
       " 'lst.wn.candidates',\n",
       " 'lst_gap.py',\n",
       " 'README',\n",
       " 'gap-score-file',\n",
       " 'lst_all.gold',\n",
       " 'scoreFA.pl',\n",
       " 'lst_test.preprocessed']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
