{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluation of models by means of lexical substitution</b><br/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "import operator\n",
    "from functools import reduce\n",
    "import pickle\n",
    "#os.listdir('small_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def prod(it):\n",
    "    return reduce(operator.mul, it, 1)\n",
    "\n",
    "def get_candidate_dict():\n",
    "    with open('lst/lst.gold.candidates','r') as f:\n",
    "        lines = map(str.strip,f.readlines())\n",
    "        d = defaultdict(list)\n",
    "        for line in lines:\n",
    "            target, candidates = line.split('::')\n",
    "            d[target] = candidates.split(';')\n",
    "    return d\n",
    "\n",
    "def cos(v1, v2):\n",
    "    # Calculates the vector cosine similarity between v1 and v2\n",
    "    # Returns a value between -1 and 1, 1 meaning exactly same\n",
    "    #  and -1 meaning exactly opposite.\n",
    "    assert len(v1) == len(v2)\n",
    "    numerator = sum([v1[i]*v2[i] for i in range(len(v1))])\n",
    "    denominator = np.sqrt(sum([x**2 for x in v1])) \\\n",
    "                * np.sqrt(sum([x**2 for x in v2]))\n",
    "    \n",
    "    return (numerator/denominator)\n",
    "\n",
    "def pcos(v1,v2):\n",
    "    return 0.5*(cos(v1,v2)+1)\n",
    "\n",
    "def add(target, sub, context):\n",
    "    # target: embedding of target word\n",
    "    # sub   : embedding of substitution word\n",
    "    # context: list of embeddings of context words\n",
    "    return (cos(sub,target) + sum([cos(sub,c) for c in context]))/(len(context)+1)\n",
    "\n",
    "def mult(target, sub,context):\n",
    "    return (pcos(sub,target) * prod([pcos(sub, c) for c in context]))**(1/(2*len(context)))\n",
    "\n",
    "def load_skipgram():\n",
    "   \n",
    "    with open('skipgram_embedding.matrix','rb') as f:\n",
    "        embed_mat = pickle.load(f)\n",
    "    print(\"Embedding loaded.\")\n",
    "    with open('i2w.skip','rb') as f:\n",
    "        int2word_skip = pickle.load(f)\n",
    "    with open('w2i.skip','rb') as f:\n",
    "        word2int_skip = pickle.load(f)\n",
    "    return embed_mat, int2word_skip, word2int_skip\n",
    "\n",
    "def get_embedding(word, embed_mat, word2int):\n",
    "    try:\n",
    "        idx = word2int[word]\n",
    "    except KeyError:\n",
    "        # KeyError will return the UNK vector\n",
    "        idx = word2int['<UNK>']\n",
    "    return embed_mat[idx,:]\n",
    "\n",
    "def word2embed_skip(embedding_mat, w2i,*input_words):\n",
    "\n",
    "    if len(input_words) > 1:\n",
    "        result = [get_embedding(x, embedding_mat, w2i) for x in input_words]\n",
    "        result = [x for x in result if x is not None]\n",
    "    else:\n",
    "        result = get_embedding(input_words[0], embedding_mat, w2i)\n",
    "    return result\n",
    "\n",
    "def result2line(target, sent_id, sorted_results):\n",
    "    line = 'RANKED\\t{}\\t{}\\t'.format(target,sent_id)\n",
    "    for (word, score) in sorted_results:\n",
    "        line += '{} {}\\t'.format(word,score)\n",
    "    line +='\\n'\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding loaded.\n",
      "EVAL 0/1710\n",
      "avg it: 0 sec\n"
     ]
    }
   ],
   "source": [
    "def eval_model(embed_func, load_func):\n",
    "    # varname_e means embedded vector of word in var <varname>\n",
    "    cand_dict = get_candidate_dict()\n",
    "    punc_set = ['.',',',':',';','_','-']\n",
    "    embedding_mat, i2w,w2i = load_func()\n",
    "    \n",
    "    with open('lst/lst_test.preprocessed','r') as f:\n",
    "        lines = list(map(str.strip,f.readlines()))\n",
    "    \n",
    "   # with open('lst.out','w') as f:\n",
    "    add_file = open('lst_add.out','w')\n",
    "    mult_file = open('lst_mult.out','w')\n",
    "    st = 0\n",
    "    dt = 0\n",
    "    l = len(lines)\n",
    "    for i,line in enumerate(lines):\n",
    "        s = time.time()\n",
    "        \n",
    "        if i%500 == 0:\n",
    "            print(\"EVAL {}/{}\".format(i,l))\n",
    "            print(\"avg it: {} sec\".format(dt))\n",
    "        target, s_id, pos, sent = line.split('\\t')\n",
    "        candidates = cand_dict[target]\n",
    "        context = [x for i,x in enumerate(sent.split(' ')) if i != int(pos) and x not in punc_set]\n",
    "        #print(i,'context')\n",
    "        context_e = [get_embedding(c,embedding_mat, w2i) for c in context]\n",
    "        #print(i,'target')\n",
    "        target_e = get_embedding(target.split('.')[0],embedding_mat, w2i)\n",
    "        \n",
    "        results_add = {}\n",
    "        results_mult = {}\n",
    "        \n",
    "        for sub in candidates:\n",
    "            #print(sub)\n",
    "            sub_e = get_embedding(sub,embedding_mat, w2i)\n",
    "            \n",
    "            add_score = add(target_e, sub_e, context_e)\n",
    "            mult_score = mult(target_e, sub_e, context_e)\n",
    "            results_add[sub] = add_score\n",
    "            results_mult[sub] = mult_score\n",
    "        add_sort = sorted(results_add.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        mult_sort = sorted(results_mult.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        add_file.write(result2line(target,s_id,add_sort))\n",
    "        mult_file.write(result2line(target,s_id, mult_sort))\n",
    "        st += time.time() - s\n",
    "        dt = st / (i+1)\n",
    "    add_file.close()\n",
    "    mult_file.close()\n",
    "    print('DONE.')\n",
    "            \n",
    "    \n",
    "eval_model(word2embed_skip, load_skipgram)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.09630829,  0.7440492 ,  0.34276482,  0.8761543 , -0.94496965,\n",
       "        0.23159432,  0.4099211 , -0.68691844,  0.3098697 ,  0.33363786,\n",
       "       -0.2250453 , -0.3840212 ,  0.14566989,  0.16685817,  0.3829214 ,\n",
       "       -0.5618807 , -0.05575426, -0.53012216, -0.08547916, -0.14512509,\n",
       "        0.46568826, -0.6449125 , -0.4510265 ,  0.8284293 ,  0.3008002 ,\n",
       "        0.103365  , -0.55712   , -0.02216346, -0.4562141 ,  0.65446734,\n",
       "       -0.54112333,  1.0685014 , -0.25909323, -0.8431133 ,  0.97710973,\n",
       "       -0.20312196, -0.5276526 , -0.5820654 , -0.5117101 ,  0.18762219,\n",
       "       -0.34834078, -0.72800124,  0.28341955,  0.16523412,  0.42910457,\n",
       "       -0.5118524 ,  0.32897094,  0.11907633, -0.20873548, -0.33772415,\n",
       "        0.4324073 , -0.4987982 , -0.25987038, -0.28694206, -0.46506748,\n",
       "        0.01246771,  1.0905099 ,  0.45066744,  0.49298775,  0.24635513,\n",
       "        0.14903821, -0.7840744 , -0.5718523 ,  0.5324328 ,  0.39959148,\n",
       "       -0.590829  ,  0.7384237 , -0.5569704 ,  0.3998689 , -0.66313106,\n",
       "       -0.13294154,  0.35731488,  0.13844198,  0.6174481 ,  0.5254624 ,\n",
       "       -0.2282317 , -0.25881386,  0.1752359 , -0.93520766, -0.27956802,\n",
       "        0.08223346,  0.25055063,  0.28852102, -0.5927217 ,  0.10836103,\n",
       "        0.5601542 , -0.5427551 , -0.38592213, -0.10314007,  0.2459874 ,\n",
       "       -0.3272547 ,  0.5643412 , -0.15839256,  0.5425087 , -0.16370595,\n",
       "       -0.6606567 ,  0.5002908 ,  0.33014533, -0.09481476, -0.03134864,\n",
       "       -0.72019786, -0.9233034 , -0.4094791 , -0.14399719, -0.02374347,\n",
       "       -0.12608875, -0.18593153, -0.6794735 ,  0.69116026, -0.113784  ,\n",
       "        0.41065514,  0.39228386, -0.18998356, -0.13573514, -0.63936037,\n",
       "       -0.3795997 ,  0.8608222 , -0.5295727 , -1.0272697 ,  0.3541665 ,\n",
       "       -0.6710749 ,  0.37735897, -0.3983933 ,  0.74888694, -0.48409852,\n",
       "        0.6655269 , -0.7695967 , -0.06939847,  0.01214229,  0.1864284 ,\n",
       "        0.5025669 ,  0.1143062 ,  0.62353224,  0.16956416, -0.585204  ,\n",
       "        0.12904596, -1.0766274 , -0.38578558,  0.40627718,  0.6447073 ,\n",
       "        0.18774502, -0.08504263, -0.48754883,  0.4547763 , -0.7552304 ,\n",
       "       -0.3108641 ,  0.24171534,  0.0509595 , -0.9191066 ,  0.36700422,\n",
       "       -0.6374713 ,  0.19405974,  0.83723944, -0.41160545, -0.2426947 ,\n",
       "        0.133848  , -0.1333188 , -0.06370315, -0.0726122 , -0.7145638 ,\n",
       "        0.00585838,  0.14269371, -0.33366847, -0.07084563,  0.11332427,\n",
       "       -0.46357268, -0.09467978,  0.2790425 , -0.26741484, -0.31774902,\n",
       "        0.7166709 ,  0.41430807,  0.56952095, -0.5039076 , -0.11458856,\n",
       "        0.3058806 , -0.5236052 ,  0.5645556 ,  0.53982204,  0.1317819 ,\n",
       "       -0.30335197, -0.58293664,  0.40361476, -0.58141494, -0.17889872,\n",
       "       -0.20073089, -0.5219549 , -0.07036766, -0.39344576,  0.11767058,\n",
       "        0.5970857 , -0.42463312, -0.04173673, -0.7608135 , -0.5026099 ,\n",
       "        0.775961  , -0.12538035,  0.47280607, -0.856126  ,  0.2333495 ,\n",
       "        0.17840968, -0.10066967, -0.55138344,  0.19216107, -0.64039165,\n",
       "        0.22344002,  0.48275888, -0.18049002, -0.7798901 , -0.08127785,\n",
       "        0.13648055,  0.75308216, -0.4735262 ,  0.03972755,  0.3425473 ,\n",
       "       -0.3435094 ,  0.18160824,  0.1730381 , -0.47973308, -0.3461655 ,\n",
       "        0.9605277 , -0.00783288, -0.5371247 ,  0.33144996,  0.0904652 ,\n",
       "       -0.07408459, -0.09062082, -0.7714098 ,  0.3990341 , -0.68544805,\n",
       "        0.0755327 ,  0.768863  , -0.3233987 , -0.3083834 , -0.2415253 ,\n",
       "       -0.6892591 , -0.00209589,  0.5444998 , -0.2895982 , -0.45505086,\n",
       "        0.7321554 , -0.6639947 ,  0.88547796, -0.5222279 , -0.64526945,\n",
       "       -0.27057952, -0.44773093,  0.40605712, -0.09482079, -0.55066854,\n",
       "       -0.07549217,  0.58701205,  0.39852798, -0.43448836, -1.0228523 ,\n",
       "       -0.42828986, -0.5455843 ,  0.17258783, -0.07578822,  0.42649886,\n",
       "       -1.3161696 , -0.15695798,  0.19093609, -0.84806466,  0.17501971,\n",
       "       -0.35311082,  0.76670945, -0.96805555, -0.06708013, -0.47665715,\n",
       "       -0.600086  , -0.6965629 , -0.1442195 ,  0.40608546,  0.06035931,\n",
       "       -0.32521018,  0.23990063,  0.30712715, -0.17841952, -0.07812843,\n",
       "       -0.30128723,  0.40090436,  0.6692046 , -0.02731564,  0.20747066,\n",
       "        0.4492998 , -0.53701   ,  0.34913173, -0.2908686 , -0.49313864,\n",
       "       -0.1885401 ,  0.8322738 , -0.5410364 , -0.07538482,  0.01779922,\n",
       "        0.37710476,  0.4229355 , -0.38406786, -0.33430213,  0.40165243],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mat, i2w,w2i = load_skipgram()\n",
    "word2embed_skip(embedding_mat, w2i, '<UNK>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'conversely'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-59d3a5d152a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conversely'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'conversely'"
     ]
    }
   ],
   "source": [
    "w2i['conversely']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "(3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "bla(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['divide',\n",
       " 'surface',\n",
       " 'perspective',\n",
       " 'aspect',\n",
       " 'conversely',\n",
       " 'other hand',\n",
       " 'area',\n",
       " 'dividing line',\n",
       " 'flank',\n",
       " 'instead',\n",
       " 'you',\n",
       " 'for us',\n",
       " 'ally',\n",
       " 'contingent',\n",
       " 'faction',\n",
       " 'hand',\n",
       " 'part',\n",
       " 'standpoint',\n",
       " 'boundary',\n",
       " 'bank',\n",
       " 'fringe',\n",
       " 'against',\n",
       " 'facet',\n",
       " 'from you',\n",
       " 'shore',\n",
       " 'edge',\n",
       " 'responsibility',\n",
       " 'team',\n",
       " 'position',\n",
       " 'view']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RESULT    find.v 71    show 0.34657\n",
    "def read_eval_line(eval_line):\n",
    "    eval_weights = []\n",
    "    segments = eval_line.split(\"\\t\")\n",
    "    #print(segments)\n",
    "    instance_id = segments[1].strip()\n",
    "    #print(instance_id)\n",
    "    for candidate_weight in segments[2:]:\n",
    "        if len(candidate_weight) > 0:\n",
    "            delimiter_ind = candidate_weight.rfind(' ')\n",
    "            candidate = candidate_weight[:delimiter_ind]\n",
    "            weight = candidate_weight[delimiter_ind:]\n",
    "            if ignore_mwe and ((len(candidate.split(' '))>1) or (len(candidate.split('-'))>1)):\n",
    "                continue\n",
    "            try:\n",
    "                eval_weights.append((candidate, float(weight)))\n",
    "            except:\n",
    "                print(\"Error appending: %s %s\" % (candidate, weight))\n",
    "\n",
    "    return instance_id, eval_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from skip_checkpoints/text8.ckpt\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph('skip_checkpoints/text8.ckpt.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('skip_checkpoints'))\n",
    "graph = tf.get_default_graph()\n",
    "embed_tensor = graph.get_tensor_by_name('embedding:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = sess.run(embed_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lst_test.gold',\n",
       " 'lst.gold.candidates',\n",
       " 'score.pl',\n",
       " 'generalized_average_precision.py',\n",
       " 'lst.wn.candidates',\n",
       " 'lst_gap.py',\n",
       " 'README',\n",
       " 'gap-score-file',\n",
       " 'lst_all.gold',\n",
       " 'scoreFA.pl',\n",
       " 'lst_test.preprocessed']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('lst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skipgram_embedding.matrix','wb') as f:\n",
    "    pickle.dump(bla,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
